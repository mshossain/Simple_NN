{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70f50940",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "576b8118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data\n",
    "np.random.seed(42)\n",
    "n_samples = 1000\n",
    "X1 = np.random.randn(n_samples)\n",
    "X2 = np.random.randn(n_samples) * 2\n",
    "# Irrelevant features\n",
    "X_noise1 = np.random.rand(n_samples) * 3\n",
    "X_noise2 = np.random.rand(n_samples) * 2\n",
    "X_noise3 = np.random.rand(n_samples) * 5\n",
    "Y = 3 * X1 + 1.5 * X2 + np.random.randn(n_samples) * 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24394f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({\n",
    "    'X1': X1,\n",
    "    'X2': X2,\n",
    "    'Noise1': X_noise1,\n",
    "    'Noise2': X_noise2,\n",
    "    'Noise3': X_noise3,\n",
    "    'Target': Y\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5525dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for training and testing\n",
    "features = data.drop('Target', axis=1).values\n",
    "target = data['Target'].values\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "features = scaler.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0078820",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f1ef70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert to tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "# DataLoader\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0fd5a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(5, 3)  # 5 inputs to 3 hidden nodes\n",
    "        self.fc2 = nn.Linear(3, 1)  # 3 hidden nodes to 1 output\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "def train_model(model, train_loader, \n",
    "                l1_strength=0.01, epochs=100):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for inputs, targets in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            l1_penalty = sum(p.abs().sum() for p in model.parameters())\n",
    "            total_loss = loss + l1_strength * l1_penalty\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e01b17f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train the model\n",
    "\n",
    "# Model with L1 regularization\n",
    "model = SimpleNN()\n",
    "trained_model = train_model(\n",
    "    model, train_loader, l1_strength=0.1)\n",
    "\n",
    "# Model with no regularization (l1_strength is zero)\n",
    "model2 = SimpleNN()\n",
    "trained_model_noRegu = train_model(\n",
    "    model2, train_loader, l1_strength=0.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1bcb7b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc1.weight weights: tensor([[-9.7806e-01, -6.1022e-01, -4.4671e-04,  6.5395e-04,  6.8184e-04],\n",
      "        [ 1.2252e+00,  1.2414e+00, -1.8125e-03, -5.0232e-06,  1.4645e-03],\n",
      "        [-6.6168e-01, -1.0257e+00, -8.8860e-04,  1.0574e-03,  6.5078e-04]])\n",
      "fc2.weight weights: tensor([[-1.2673,  1.6169, -1.4445]])\n"
     ]
    }
   ],
   "source": [
    "# Check the weights\n",
    "for name, param in trained_model.named_parameters():\n",
    "    if \"weight\" in name:\n",
    "        print(f\"{name} weights: {param.data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a05f9244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc1.weight weights: tensor([[ 0.6880,  1.1571, -0.3001,  0.2020, -0.0301],\n",
      "        [-1.0862, -1.2773, -0.0989,  0.0703,  0.0471],\n",
      "        [ 1.1677,  0.6130,  0.1170, -0.0979,  0.0830]])\n",
      "fc2.weight weights: tensor([[ 0.9468, -1.4518,  1.1074]])\n"
     ]
    }
   ],
   "source": [
    "# Check the weights\n",
    "for name, param in trained_model_noRegu.named_parameters():\n",
    "    if \"weight\" in name:\n",
    "        print(f\"{name} weights: {param.data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56ba9cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Model evaluation using Test data #######\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():  # Turn off gradients\n",
    "        predictions = model(X_test)\n",
    "        loss = F.mse_loss(predictions, y_test)  # Compute the mean squared error loss\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97a8fcbd-ee14-4c17-b690-1832da1ac5be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error with L1 Regularization: 0.6119637489318848\n",
      "Mean Squared Error with No Regularization: 0.5939650535583496\n"
     ]
    }
   ],
   "source": [
    "# Evaluate both models\n",
    "mse_l1 = evaluate_model(trained_model, X_test, y_test)\n",
    "mse_no_regu = evaluate_model(trained_model_noRegu, X_test, y_test)\n",
    "\n",
    "print(f\"Mean Squared Error with L1 Regularization: {mse_l1}\")\n",
    "print(f\"Mean Squared Error with No Regularization: {mse_no_regu}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2aea38-1801-4837-a8c6-fcaa22a4ecbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
